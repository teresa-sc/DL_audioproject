{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started\n",
    "This is a minimal example to show you how to load models and data and extract hidden representations of your data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example with models and data from huggingface\n",
    "\n",
    "You can find many models and datasets on [huggingface.co](https://huggingface.co/), check out https://superbbenchmark.github.io/ for some inspiration for tasks and models. \n",
    "\n",
    "You can of course also choose any other model and task you want to work with (within audio), but I would strongly recommend to use a transformer based model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model and data from huggingface \n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import Wav2Vec2Model, Wav2Vec2FeatureExtractor\n",
    "\n",
    "# load pretrained model (here wav2vec2)\n",
    "# you can find many other models on huggingface.co\n",
    "processor = Wav2Vec2FeatureExtractor.from_pretrained(\"facebook/wav2vec2-base\")\n",
    "model = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-base\")\n",
    "\n",
    "# load data\n",
    "# you can find many other datasets on huggingface.co\n",
    "dataset = load_dataset(\"speech_commands\", \"v0.02\")\n",
    "\n",
    "#prepapre an example dataset\n",
    "data = dataset[\"test\"]\n",
    "data = data.filter(lambda example: example[\"label\"] in range(11)) # lets only keep 10 classes\n",
    "data = data.shuffle(seed=42)\n",
    "data = data.select(range(500))\n",
    "# save labels for later analysis\n",
    "np.save(\"outputs/labels.npy\", data[\"label\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to extract representations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # you should use a GPU for this task, otherwise it will be very slow\n",
    "\n",
    "def extract_features(model, processor, dataset, output_dir, num_layers=13, num_features=768):\n",
    "    model.to(device)\n",
    "\n",
    "    #initialize hidden states tensor to avoid itereative concatenation which is very slow\n",
    "    hidden_states = torch.zeros((len(dataset), num_layers, num_features))\n",
    "    \n",
    "    # iterate over the dataset\n",
    "    for i, example in enumerate(tqdm(dataset)):\n",
    "        #preprocess the data, check your data how to call your audio file (here it is [\"audio\"][\"array\"])\n",
    "        inputs = processor(example[\"audio\"][\"array\"], return_tensors=\"pt\", padding='max_length', max_length=16000, sampling_rate=16000).input_values.to(device)\n",
    "       \n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs, output_hidden_states=True, return_dict=True)\n",
    "        \n",
    "        # average the hidden states over the time axis for each layer j\n",
    "        for j, hidden_state in enumerate(outputs.hidden_states):\n",
    "            hs_mean = torch.mean(hidden_state, dim=1)\n",
    "            hidden_states[i, j] = hs_mean\n",
    "        \n",
    "        #optional saving after 100 steps\n",
    "        # depending on the size of your dataset this process can time out so better save intermediate results\n",
    "        if i>0 and i%100 == 0:\n",
    "            np.save(os.path.join(output_dir, f\"hidden_states.npy\"), hidden_states.cpu().numpy())\n",
    "   \n",
    "    np.save(os.path.join(output_dir, f\"hidden_states.npy\"), hidden_states.cpu().numpy())\n",
    "\n",
    "\n",
    "# run a small experiment with 100 random samples\n",
    "\n",
    "extract_features(model, processor, data, \"outputs\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the hidden representations\n",
    "\n",
    "Here we use TSNE, you can also use PCA, UMAP or PHATE or any other method you like.\n",
    "This is useful to give a first intuition on whats happening inside our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# lets load the hidden states and check the shape\n",
    "hidden_states = np.load(\"outputs/hidden_states.npy\")\n",
    "labels = np.load(\"outputs/labels.npy\")\n",
    "unique_labels = np.unique(labels)\n",
    "\n",
    "# visualize the hidden states using tsne of a few layers\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for idx, layer in enumerate([0, 6, 12]):\n",
    "    X_embedded = TSNE().fit_transform(hidden_states[:, layer, :])\n",
    "    ax = axes[idx]\n",
    "    for i in range(len(unique_labels)):\n",
    "        ax.scatter(X_embedded[labels == unique_labels[i], 0], X_embedded[labels == unique_labels[i], 1], marker='o')\n",
    "    ax.set_title(f\"Layer {layer}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a similarity analysis across layers\n",
    "\n",
    "Here we use three common methods: CKA, cosine similarity and mutual kNN\n",
    "\n",
    "These papers are good to check out for similarity analysis: \n",
    "\n",
    "\n",
    "Kornblith, S., Norouzi, M., Lee, H. &amp; Hinton, G.. (2019). Similarity of Neural Network Representations Revisited. <i>Proceedings of the 36th International Conference on Machine Learning</i>, in <i>Proceedings of Machine Learning Research</i> 97:3519-3529 Available from https://proceedings.mlr.press/v97/kornblith19a.html.\n",
    "\n",
    "Huh, M., Cheung, B., Wang, T., & Isola, P. (2024). The platonic representation hypothesis. arXiv preprint arXiv:2405.07987. https://arxiv.org/abs/2405.07987  *(this one is generally intresting to read but not necessary for this project)*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from src.similarity_metrics import cka, mutual_knn, cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "hidden_states = np.load(\"hidden_states/hidden_states.npy\")\n",
    "\n",
    "num_layers = hidden_states.shape[1]\n",
    "num_samples = hidden_states.shape[0]\n",
    "hidden_states = torch.tensor(hidden_states)\n",
    "\n",
    "cka_matrix = np.zeros((num_layers, num_layers))\n",
    "for i in range(num_layers):\n",
    "    for j in range(num_layers):\n",
    "        cka_matrix[i, j] = cka(hidden_states[:, i, :], hidden_states[:, j, :])\n",
    "\n",
    "knn_matrix = np.zeros((num_layers, num_layers))\n",
    "for i in range(num_layers):\n",
    "    for j in range(num_layers):\n",
    "        knn_matrix[i, j] = mutual_knn(hidden_states[:, i, :], hidden_states[:, j, :], topk=5)\n",
    "\n",
    "\n",
    "# Compute cosine similarity\n",
    "cosine_matrix = np.zeros((num_layers, num_layers))\n",
    "for i in range(num_layers):\n",
    "    for j in range(num_layers):\n",
    "        cosine_matrix[i, j] = cosine_similarity(hidden_states[:, i, :], hidden_states[:, j, :]).trace()/num_samples\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "\n",
    "sns.heatmap(cka_matrix, ax=axes[0], cmap=\"viridis\")\n",
    "axes[0].set_title(\"CKA Similarity Matrix Across Layers\")\n",
    "\n",
    "sns.heatmap(knn_matrix, ax=axes[1], cmap=\"viridis\")\n",
    "axes[1].set_title(\"Mutual kNN Similarity Matrix Across Layers\")\n",
    "axes[1].set_xlabel(\"Layers\")\n",
    "axes[1].set_ylabel(\"Layers\")\n",
    "\n",
    "sns.heatmap(cosine_matrix, ax=axes[2], cmap=\"viridis\")\n",
    "axes[2].set_title(\"Cosine Similarity Matrix Across Layers\")\n",
    "axes[2].set_xlabel(\"Layers\")\n",
    "axes[2].set_ylabel(\"Layers\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convexity analysis\n",
    "\n",
    "This is based on my prior work and you do not have to do this in your project. But it can give a nice intuition of where your model forms convex regions of the classes you are intrested in and which layers \"know\" the most about your task. \n",
    "\n",
    "Check out these papers:\n",
    "\n",
    "Dorszewski, T., Tětková, L., & Hansen, L. K. (2024). Convexity-based Pruning of Speech Representation Models. arXiv preprint arXiv:2408.11858. https://arxiv.org/pdf/2408.11858 *(Recommended to read)*\n",
    "\n",
    "Tetková, L., Brüsch, T., Scheidt, T. K., Mager, F. M., Aagaard, R. Ø., Foldager, J., ... & Hansen, L. K. (2023). On convex conceptual regions in deep network representations. https://arxiv.org/pdf/2305.17154 *(Introduction of convexity score, additional read if you want to know more)*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.convexity import graph_convexity\n",
    "\n",
    "hidden_states = np.load(\"outputs/hidden_states.npy\")\n",
    "labels = np.load(\"outputs/labels.npy\")\n",
    "\n",
    "# Compute convexity, this can take some time depending on the size of the dataset\n",
    "convexity,_ = graph_convexity(hidden_states, labels, num_neighbours=10)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot([x[0] for x in convexity])\n",
    "plt.xlabel(\"Layers\")\n",
    "plt.ylabel(\"Convexity\")\n",
    "plt.title(\"Convexity of Words Across Layers\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you will see if everything worked out, the 10 different words (classes) form convex regions especially in middle layers, eventhough the model was never specifically trained to distinguish words.\n",
    "You can check out my paper from above to see how this changes when you finetune a model. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning\n",
    "\n",
    "I will update this soon and have some examples of pruning.\n",
    "\n",
    "Here are some papers you can check out for now if you are really eager: \n",
    "\n",
    "Dorszewski, T., Jacobsen, A. K., Tětková, L., & Hansen, L. K. (2024). How Redundant Is the Transformer Stack in Speech Representation Models?. arXiv preprint arXiv:2409.16302. https://arxiv.org/pdf/2409.16302 *(result from a student project this year, recommended to read)*\n",
    "\n",
    "Y. Peng, K. Kim, F. Wu, P. Sridhar and S. Watanabe, \"Structured Pruning of Self-Supervised Pre-Trained Models for Speech Recognition and Understanding,\" ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), https://ieeexplore.ieee.org/abstract/document/10095780 \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "convex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
